{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scripts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb1 = pd.read_csv(\"zippedData/imdb.name.basics.csv.gz\")\n",
    "imdb2 = pd.read_csv(\"zippedData/imdb.title.akas.csv.gz\")\n",
    "imdb3 = pd.read_csv(\"zippedData/imdb.title.basics.csv.gz\")\n",
    "imdb4 = pd.read_csv(\"zippedData/imdb.title.crew.csv.gz\")\n",
    "imdb5 = pd.read_csv(\"zippedData/imdb.title.principals.csv.gz\")\n",
    "imdb6 = pd.read_csv(\"zippedData/imdb.title.ratings.csv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Web Scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning primary keys in imdb dfs\n",
    "imdb2['title_id'] = imdb2['title_id'].str.strip()\n",
    "imdb3['tconst'] = imdb3['tconst'].str.strip()\n",
    "imdb4['tconst'] = imdb4['tconst'].str.strip()\n",
    "imdb5['tconst'] = imdb5['tconst'].str.strip()\n",
    "imdb6['tconst'] = imdb6['tconst'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping duplicates\n",
    "imdb2.drop_duplicates(subset=['title_id'], inplace=True)\n",
    "imdb3.drop_duplicates(subset=['tconst'], inplace=True)\n",
    "imdb4.drop_duplicates(subset=['tconst'], inplace=True)\n",
    "imdb5.drop_duplicates(subset=['tconst'], inplace=True)\n",
    "imdb6.drop_duplicates(subset=['tconst'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing web scrapes\n",
    "web_scrape1 = pd.read_csv('scraped_data/imdb_monetary_data_16590.csv')\n",
    "web_scrape1.set_index(['title_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_scrape2 = pd.read_csv('scraped_data/imdb_monetary_data_16591_to_25214_.csv')\n",
    "web_scrape2.set_index(['title_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_scrape3 = pd.read_csv('scraped_data/imdb_monetary_data_29214_.csv')\n",
    "web_scrape3.set_index(['title_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_scrape4 = pd.read_csv('scraped_data/imdb_monetary_data_33736_.csv')\n",
    "web_scrape4.set_index(['title_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_scrape5 = pd.read_csv('scraped_data/imdb_monetary_data_49857_.csv')\n",
    "web_scrape5.set_index(['title_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_scrape6 = pd.read_csv('scraped_data/imdb_monetary_data_65930_.csv')\n",
    "web_scrape6.set_index(['title_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_scrape7 = pd.read_csv('scraped_data/imdb_monetary_data_67456_.csv')\n",
    "web_scrape7.set_index(['title_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_scrape8 = pd.read_csv('scraped_data/imdb_monetary_data_77436_.csv')\n",
    "web_scrape8.set_index(['title_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_scrape9 = pd.read_csv('scraped_data/imdb_monetary_data_102849_.csv')\n",
    "web_scrape9.set_index(['title_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating webscraped data\n",
    "web_scrape = pd.concat([web_scrape1, web_scrape2, web_scrape3, web_scrape4, web_scrape5, web_scrape6, web_scrape7, web_scrape8, web_scrape9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unnamed column\n",
    "web_scrape.drop(['Unnamed: 0'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning title_id (index)\n",
    "web_scrape.index = web_scrape.index.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging imdb2 - imdb6\n",
    "df = web_scrape.merge(imdb2, left_on=web_scrape.index, right_on=['title_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(imdb3, left_on=['title_id'], right_on=['tconst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(imdb4, left_on=['title_id'], right_on=['tconst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(imdb5, left_on=['title_id'], right_on=['tconst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(imdb6, how='left', left_on=['title_id'], right_on=['tconst'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating Director Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "directors1 = pd.read_csv('scraped_data/imdb_name_list_202_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "directors2 = pd.read_csv('scraped_data/imdb_name_list_304_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "directors3 = pd.read_csv('scraped_data/imdb_name_list_3016_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "directors4 = pd.read_csv('scraped_data/imdb_name_list_7799_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "directors5 = pd.read_csv('scraped_data/imdb_name_list_13173_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "directors_names = pd.concat([directors1, directors2, directors3, directors4, directors5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Director Names with Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding in scraped directors names\n",
    "df = df.merge(directors_names, left_on=['directors'], right_on=['name_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping duplicates by unique title_id number\n",
    "df.drop_duplicates(subset='title_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unnecessary columns\n",
    "df.drop(['ordering_x', 'language', 'attributes', 'original_title', 'Runtime', 'is_original_title', 'tconst_x', 'tconst_y', 'types', 'category', 'job', 'characters', 'ordering_y', 'title', 'nconst', 'region', 'writers', 'directors', 'Unnamed: 0', 'name_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Null Values\n",
    "df = df.dropna(subset=['Opening Weekend USA', 'Gross USA', 'Cumulative Worldwide Gross'], how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative Worldwide Gross replace NaN with 0\n",
    "df['Cumulative Worldwide Gross'] = df['Cumulative Worldwide Gross'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping a few rows with strange string values\n",
    "df = df.drop(df.loc[df['Cumulative Worldwide Gross'].str.contains('INR') == True].index)\n",
    "df = df.drop(df.loc[df['Cumulative Worldwide Gross'].str.contains('NPR') == True].index)\n",
    "df = df.drop(df.loc[df['Cumulative Worldwide Gross'].str.contains('AUD') == True].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the currency strings to be usable integers\n",
    "df['Cumulative Worldwide Gross'] = df['Cumulative Worldwide Gross'].map(lambda x: clean_currency(x))\n",
    "df['Cumulative Worldwide Gross'] = pd.to_numeric(df['Cumulative Worldwide Gross'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gross USA \n",
    "df['Gross USA'] = df['Gross USA'].fillna(0)\n",
    "df['Gross USA'] = df['Gross USA'].map(lambda x: clean_currency(x))\n",
    "df['Gross USA'] = pd.to_numeric(df['Gross USA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening Weekend USA\n",
    "df['Opening Weekend USA'] = df['Opening Weekend USA'].fillna(0)\n",
    "df['Opening Weekend USA'] = df['Opening Weekend USA'].map(lambda x: clean_currency(x))\n",
    "df['Opening Weekend USA'] = pd.to_numeric(df['Opening Weekend USA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Budget\n",
    "df['Budget'] = df['Budget'].map(lambda x: clean_currency(x))\n",
    "df['Budget'] = df['Budget'].fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquiring unique currencies to be able to convert foreign currencies to USD\n",
    "budget_curr = df['Budget'].tolist()\n",
    "list_of_curr = find_currencies(budget_curr).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switched null values to '0' string in order to apply conversion function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Budget.fillna('0', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply conversion function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Budget'] = df['Budget'].apply(lambda x: conversion_rates(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17172, 13)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Genres Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genres'] = df['genres'].fillna('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genres'] = df['genres'].map(lambda x: list(x.split(',')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename Director Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'name':'director'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Budgets < 1000usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Budget'] = df['Budget'].replace(0.0, np.nan)\n",
    "df = df.drop(df[df.Budget < 1000].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Profit and Roi Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Profit'] = df['Cumulative Worldwide Gross']-df['Budget']\n",
    "df['Roi'] = ((df['Cumulative Worldwide Gross'] - df['Budget'])/df['Budget'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Budget'] = df['Budget'].fillna(0)\n",
    "df['Budget'] = df['Budget'].astype(int)\n",
    "df['Profit'] = df['Profit'].fillna(0)\n",
    "df['Profit'] = df['Profit'].astype(int)\n",
    "df['Roi'] = df['Roi'].replace(np.inf, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Genre Columns Added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of unique genres found in our table\n",
    "list_of_genres = [row[0] for row in df['genres']]\n",
    "l_o_genres = list(set(list_of_genres))\n",
    "l_o_genres.remove('NaN')\n",
    "\n",
    "# creating a matrix of zeros that matches the length of our table and the width of the list of unique genres\n",
    "zero_matrix = np.zeros((len(df), len(l_o_genres)))\n",
    "dummies = pd.DataFrame(zero_matrix, columns=l_o_genres)\n",
    "\n",
    "# adding 1s to each dummy cell whose genre is listed in the genres column\n",
    "for i, gen in enumerate(df.genres):\n",
    "    indices = dummies.columns.get_indexer(gen)\n",
    "    dummies.iloc[i, indices] = 1\n",
    "\n",
    "# merging the dummy matrix to our table\n",
    "df = df.merge(dummies, how='outer', on=df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'key_0':'title_id'}, inplace=True)\n",
    "df.set_index(['primary_title'], inplace=True)\n",
    "df.drop(['title_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make df a .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('master_table.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
